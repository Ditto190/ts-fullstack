# Behavior System Quick Reference for Agents

> **ESSENTIAL**: Read this before working with behaviors or value hypotheses

## ğŸ¯ Core Principles (NEVER VIOLATE)

1. **Tests Define Behaviors** - @behavior headers live in TEST files, NOT implementation files
2. **TDD Workflow** - Write tests first (Given-When-Then), then implement
3. **Status from Tests** - @status is COMPUTED from test results (pass/fail), never manual
4. **Automation Computes Everything** - NEVER manually edit behaviors.json or dashboard files
5. **Semantic Taxonomy** - Use `DOMAIN.ENTITY.OPERATION` format (no arbitrary numbers)
6. **Value-Driven Prioritization** - Use VH scoring to determine what to build

## ğŸ“‹ Agent Workflow (TDD-First)

### When Starting a VH - Analyze & Stub Tests

1. **Review VH requirements** - Check `vh-dashboard.md` for linked behaviors
2. **Identify missing behaviors** - Compare VH requirements to existing test files
3. **Create test stubs** - Write @behavior headers + skeleton tests (Given-When-Then)
4. **Sync registry** - `yarn behaviors:sync` updates behaviors.json from test files

### Behavior Test Structure

**Location:** Tests define behaviors, implementation files just implement

```
apps/api/
  src/
    routes/
      users.ts                    # Implementation (no @behavior)
      users.test.ts               # @behavior USER.ROUTE.CREATE

packages/db/
  src/
    schema/
      users.ts                    # Implementation (no @behavior)
      users.test.ts               # @behavior DB.SCHEMA.USERS
```

**Test file with @behavior header:**

```typescript
/**
 * @behavior DOMAIN.ENTITY.OPERATION
 * @priority CRITICAL | HIGH | MEDIUM | LOW
 * @effort TRIVIAL | SMALL | MEDIUM | LARGE | XLARGE
 * @theme INTELLIGENCE | ACCELERATION | SYNTHESIS | ALIGNMENT | AUTOMATION
 * @persona ARCHITECT | PRACTITIONER | EXPLORER | SYNTHESIZER
 * @why Clear explanation of value and problem being solved
 * @success Measurable success criteria
 * @who User story: "As X, I want Y, so that Z"
 * @what Acceptance criteria (Given/When/Then)
 * @linkedVH VALUE.HYPOTHESIS.ID.VALIDATE
 */

import { describe, test, expect } from 'vitest';

describe('DOMAIN.ENTITY.OPERATION', () => {
  describe('Given [context]', () => {
    test('When [action], Then [outcome]', () => {
      // TODO: Implement test
      expect(true).toBe(false); // TDD: Start with failing test
    });
  });
});
```

**NO @status field** - Computed automatically:
- All tests passing â†’ DONE
- Some tests failing â†’ IN_PROGRESS
- No tests/all fail â†’ PLANNED

**Then run:**
```bash
yarn behaviors:sync    # Scans test files, computes status from test results
```

### When Creating a Value Hypothesis

Edit `.flow/value-hypotheses.json` (source data only):

```json
{
  "DOMAIN.ENTITY.OPERATION.VALIDATE": {
    "id": "DOMAIN.ENTITY.OPERATION.VALIDATE",
    "tier": "FOUNDATION",
    "linkedBehaviors": ["DOMAIN.ENTITY.OPERATION"],
    "statement": "IF we do X, THEN we achieve Y value",
    "valueDomains": ["TECHNICAL", "LEARNING", "CAPABILITY", "EXPERIENTIAL"],
    "valuePotential": {
      "overall": 0.82,      // Auto-computed: (impact Ã— confidence) / (effort Ã— (2-urgency))
      "impact": 0.9,        // 0-1: Potential value impact
      "confidence": 0.8,    // 0-1: Confidence in achieving value
      "effort": 0.3,        // 0-1: Implementation effort (lower = better)
      "urgency": 0.95       // 0-1: Time sensitivity
    },
    "dependencies": ["OTHER.VH.ID"],
    "blocks": ["DOWNSTREAM.VH.ID"],
    "createdAt": "2025-10-14T00:00:00Z"
  }
}
```

**Then run:**
```bash
yarn vh:summary    # Auto-computes views/stats, generates dashboard
```

## ğŸš« NEVER DO THIS

âŒ Put @behavior headers in implementation files (they belong in TESTS)
âŒ Manually set @status field (it's computed from test results)
âŒ Manually edit `behaviors.json` (auto-generated from test files)
âŒ Manually edit views/stats in `value-hypotheses.json` (computed by automation)
âŒ Manually edit `.flow/*.md` dashboard files (auto-generated)
âŒ Use arbitrary IDs like `VH-1`, `BEHAVIOR-42` (use semantic taxonomy)
âŒ Create summary docs instead of editing individual files (no shortcuts)
âŒ Skip value scoring for VHs (resource optimization is core to Flow)
âŒ Skip writing tests (behaviors without tests = not tracked)

## âœ… ALWAYS DO THIS

âœ“ Define behaviors in TEST files via `@behavior` headers
âœ“ Write tests BEFORE implementation (TDD workflow)
âœ“ Use Given-When-Then structure in tests matching @what
âœ“ Run `yarn behaviors:sync` after creating/changing test files
âœ“ Run `yarn vh:summary` after editing value-hypotheses.json
âœ“ Use semantic taxonomy: `DOMAIN.ENTITY.OPERATION[.QUALIFIER]`
âœ“ Let automation compute all derived data (status, views, stats, dashboards)
âœ“ Link VHs to Behaviors via `linkedBehaviors` array (1:N relationship)
âœ“ Score every VH with impact/confidence/effort/urgency
âœ“ Let test results determine behavior status (DONE = all passing)

## ğŸ“Š Value Hypothesis Scoring

**Value-driven prioritization:**

Work through VHs in descending order of `valuePotential.overall` score. Higher scores indicate higher potential value delivery.

**Value Score Formula:**
```
overall = (impact Ã— confidence) / (effort Ã— (2 - urgency))
```

Where:
- **impact**: 0-1, potential value impact
- **confidence**: 0-1, confidence in achieving value
- **effort**: 0-1, implementation effort (lower is better)
- **urgency**: 0-1, time sensitivity

## ğŸ”— VH-Behavior Relationship

```
ValueHypothesis â†’ Behavior/Behavior â†’ Implementation
(spawns)          (spawns)           (validates VH)
```

**Key Design:**
- VHs link to Behaviors: `"linkedBehaviors": ["BEHAVIOR.ID.HERE"]`
- Behaviors do NOT link back to VHs (single source of truth)
- VHs can link to multiple behaviors (1:N relationship)

## ğŸ“ File Structure

```
.flow/
â”œâ”€â”€ README.md                    â† YOU ARE HERE (read first!)
â”œâ”€â”€ behavior-management.md       â† Full documentation
â”œâ”€â”€ taxonomy.yaml                â† Domain/operation definitions
â”œâ”€â”€ value-hypotheses.json        â† SOURCE DATA (edit this)
â”œâ”€â”€ vh-dashboard.md              â† AUTO-GENERATED (don't edit)
â”œâ”€â”€ behaviors.md                 â† AUTO-GENERATED (don't edit)
â”œâ”€â”€ roadmap.md                   â† AUTO-GENERATED (don't edit)
â”œâ”€â”€ progress.md                  â† AUTO-GENERATED (don't edit)
â”œâ”€â”€ backlog.md                   â† AUTO-GENERATED (don't edit)
â”œâ”€â”€ behavior-sync.ts             â† Syncs @behavior headers â†’ behaviors.json
â”œâ”€â”€ behavior-validate.ts         â† Validates @behavior headers
â”œâ”€â”€ behavior-summary.ts          â† Generates dashboard views
â”œâ”€â”€ behavior-search.ts           â† Search behaviors by pattern
â””â”€â”€ vh-summary.ts                â† Computes VH views/stats/dashboard

behaviors.json                    â† AUTO-GENERATED (don't edit)
```

## ğŸ“ Semantic Taxonomy Examples

**Good:**
- `USER.ROUTE.CREATE` - Create user API route
- `DB.SCHEMA.USERS` - User database schema
- `UI.BUTTON.COMPONENT` - Button UI component
- `API.AUTH.MIDDLEWARE` - Authentication middleware

**Bad:**
- `BEHAVIOR-1` - No semantic meaning
- `VH-42` - Arbitrary numbering
- `create` - Missing domain/entity
- `user-create` - Wrong format (use dots, not hyphens)

## ğŸš€ Common Commands

```bash
# Behavior Management (Test-Driven)
yarn behaviors:sync        # Scan test files â†’ behaviors.json, compute status from vitest
yarn behaviors:validate    # Validate @behavior headers in test files
yarn behaviors:summary     # Generate all dashboard views
yarn behaviors:search      # Search behaviors by keyword

# Value Hypothesis Management
yarn vh:summary          # Compute views/stats, generate dashboard
yarn vh:dashboard        # View VH dashboard in terminal

# Testing (Status Computation)
yarn test                # Run vitest (status computed from results)
yarn test:watch          # Run tests in watch mode

# Quality Gates
yarn build               # Ensure all packages compile
yarn lint:check          # Ensure all linting passes
```

## âš¡ Quick Decision Tree

```
Starting a VH?
â”œâ”€ YES â†’ Review vh-dashboard.md â†’ Identify missing behaviors â†’ Create test stubs with @behavior â†’ yarn behaviors:sync
â”‚
Creating new functionality?
â”œâ”€ YES â†’ Create test file with @behavior header â†’ Write failing tests (TDD) â†’ Implement â†’ Tests pass â†’ yarn behaviors:sync
â”‚
Are you proposing a hypothesis about value?
â”œâ”€ YES â†’ Add to value-hypotheses.json â†’ yarn vh:summary
â”‚
Want to check behavior status?
â”œâ”€ YES â†’ Run tests â†’ yarn behaviors:sync (status computed from test results)
â”‚
Are you updating VH status?
â”œâ”€ YES â†’ Update value-hypotheses.json â†’ yarn vh:summary
â”‚
Need to see current priorities?
â”œâ”€ Behaviors â†’ cat .flow/roadmap.md
â”œâ”€ VHs â†’ yarn vh:dashboard
â”‚
Need to know what to build next?
â””â”€ Check vh-dashboard.md â†’ Execute highest-value incomplete VH
```

---

**Remember:** The behavior system exists to remove cognitive overhead from agents. Let automation handle status tracking, dashboard generation, and registry management so you can focus on building value through TDD.

**When in doubt:**
- Write tests first (they define what "done" means)
- Run `yarn behaviors:sync` (safe, idempotent, computes status from tests)
- Let test results determine behavior status (no manual tracking)
